# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dnLR3cyha1D8yV_FpJRQlX4ntys5wD4j
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms

from PIL import Image
import matplotlib.image as mpimg
import matplotlib.pyplot as plt

#CPU 
torch.manual_seed(11)
#GPU
torch.cuda.manual_seed_all(11)

def im_convert(tensor):
  image = tensor.to("cpu").clone().detach()
  image = image.numpy().squeeze()
  return image

def printthis(image_tensor):
  plt.imshow(im_convert(image_tensor))
  plt.show()

class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    
    self.conv1 = nn.Conv2d(1, 10, kernel_size = 5, stride=1)
    self.conv2 = nn.Conv2d(10, 10, kernel_size = 5, stride=1)
    self.pool = nn.MaxPool2d(kernel_size = 2,stride = 2)
    self.fc1 = nn.Linear(4*4*10, 200)
    self.fc2 = nn.Linear(200, 10)
    
  def forward (self,x):
    x = F.relu(self.conv1(x))
    x = self.pool(x)
    x = F.relu(self.conv2(x))
    x = self.pool(x)
    x = x.view(-1, 4*4*10)
    x = F.relu(self.fc1(x))
    x = self.fc2(x)
    
    return x

train_loader = torch.utils.data.DataLoader(
          datasets.MNIST('../data', train=True, download=True,
                    transform= transforms.Compose([
                        transforms.ToTensor()
                        ])),
                          batch_size=100,shuffle=True)

validation_loader = torch.utils.data.DataLoader(
          datasets.MNIST('../data', train=False, download=True,
                    transform= transforms.Compose([
                        transforms.ToTensor()
                        ])),
                          batch_size=100,shuffle=True)

test_loader = torch.utils.data.DataLoader(
          datasets.MNIST('../data', train=False, download=True,
                    transform= transforms.Compose([
                        transforms.ToTensor()
                        ])),
                          batch_size=100,shuffle=True)


image = train_loader.dataset[0]
printthis(image[0])

model = Net().cuda()

optimizer = optim.SGD(model.parameters(),lr=0.01)
criterion = nn.CrossEntropyLoss()

list_error = []
list_acc = []
list_error_v = []
list_acc_v = []
for i in range(10):
    total_loss =0
    total_acc =0
    total_loss_v =0
    total_acc_v =0
    for images, labels in train_loader:
        images = images.cuda()
        labels = labels.cuda()
      
        optimizer.zero_grad()
        output = model(images)
      
        loss = criterion(output, labels)
        loss.backward()
        optimizer.step()
      
        total_loss +=loss.item()
        total_acc += torch.sum(torch.max(output,dim=1)[1]==labels).item()*1.0
    

    for images_v, labels_v in validation_loader:
        images_v = images_v.cuda()
        labels_v = labels_v.cuda()
        output_v = model(images_v)
        loss = criterion(output_v, labels_v)
        
        total_loss_v +=loss.item()
        total_acc_v += torch.sum(torch.max(output_v,dim=1)[1]==labels_v).item()
      
    list_error_v.append(total_loss_v/len(validation_loader.dataset))
    list_acc_v.append(total_acc_v/len(validation_loader.dataset)*100.0)
      
    list_error.append(total_loss/len(train_loader.dataset))
    list_acc.append(total_acc/len(train_loader.dataset)*100.0)

print("Trainig complete")




fig, ax = plt.subplots(nrows=1, ncols=2)
ax[0].plot(list_error, 'r',label="Train")
ax[0].plot(list_error_v, 'g', label="Validation")
ax[0].set_title("Grafik error")
ax[0].set_ylabel("Error (cross-entropy)")
ax[0].set_xlabel("Epoch")
ax[0].legend()
ax[1].plot(list_acc, 'r',label="Train")
ax[1].plot(list_acc_v, 'g', label="Validation")
ax[1].set_title("Grafik akurasi")
ax[1].set_ylabel("Accuracy")
ax[1].set_xlabel("Epoch")
ax[1].legend()
plt.show()

total_acc = 0
for images,labels in test_loader:
  images = images.cuda()
  labels = labels.cuda()
  output = model(images)
  total_acc+=torch.sum(torch.max(output,dim=1)[1]==labels).item()

print("Accurasi Test: ",(total_acc/len(test_loader.dataset))*100.0)